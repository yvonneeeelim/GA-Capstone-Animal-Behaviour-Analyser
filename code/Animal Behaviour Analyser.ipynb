{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9762b48e",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Capstone Project: Animal Behaviour Analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e537f",
   "metadata": {},
   "source": [
    "## Part 1: Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc76c0d",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672b6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skimage as ski\n",
    "from PIL import Image\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense,BatchNormalization, Flatten, MaxPool2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.layers import Conv2D, Reshape\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from keras.backend import epsilon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4703fb",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b4a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out the data to train and validation directories\n",
    "# In each directories, classify each class in the subdirectory\n",
    "\n",
    "base_dir = '../data'\n",
    "train_dir = os.path.join(base_dir, 'train_data')\n",
    "validation_dir = os.path.join(base_dir, 'validation_data')\n",
    "\n",
    "# Train Data\n",
    "# Directory with our training Angry Dog pictures\n",
    "train_angry_dir = os.path.join(train_dir, 'angry')\n",
    "\n",
    "# Directory with our training Happy Dog pictures\n",
    "train_happy_dir = os.path.join(train_dir, 'happy')\n",
    "\n",
    "# Directory with our training Relaxed Dog pictures\n",
    "train_relaxed_dir = os.path.join(train_dir, 'relaxed')\n",
    "\n",
    "# Directory with our training Sad Dog pictures\n",
    "train_sad_dir = os.path.join(train_dir, 'sad')\n",
    "\n",
    "# Validation Data\n",
    "# Directory with our validation Angry Dog pictures\n",
    "validation_angry_dir = os.path.join(validation_dir, 'angry')\n",
    "\n",
    "# Directory with our validation Happy Dog pictures\n",
    "validation_happy_dir = os.path.join(validation_dir, 'happy')\n",
    "\n",
    "# Directory with our validation Relaxed Dog pictures\n",
    "validation_relaxed_dir = os.path.join(validation_dir, 'relaxed')\n",
    "\n",
    "# Directory with our validation Sad Dog pictures\n",
    "validation_sad_dir = os.path.join(validation_dir, 'sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584b975",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19200e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f024302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = [train_angry_dir, train_happy_dir, train_relaxed_dir, train_sad_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder for the specific class you want to plot\n",
    "class_folder = train_happy_dir\n",
    "\n",
    "# Get a list of image files in the specified folder\n",
    "image_files = os.listdir(train_happy_dir)[:5] # Limit to the first 5 images\n",
    "\n",
    "# Create subplots for the images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(image_files), figsize=(15, 3))\n",
    "\n",
    "# Load and plot the images\n",
    "for i, filename in enumerate(image_files):\n",
    "    image_path = os.path.join(train_happy_dir, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')  # Hide axis\n",
    "\n",
    "plt.suptitle(\"Happy Dogs\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341715fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder for the specific class you want to plot\n",
    "class_folder = train_relaxed_dir\n",
    "\n",
    "# Get a list of image files in the specified folder\n",
    "image_files = glob.glob(class_folder + '/*.jpg')[:5]  # Limit to the first 5 images\n",
    "\n",
    "# Create subplots for the images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(image_files), figsize=(12, 3))\n",
    "\n",
    "# Load and plot the images\n",
    "for i, filename in enumerate(image_files):\n",
    "    image = ski.io.imread(filename)\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')  # Hide axis\n",
    "\n",
    "plt.suptitle(\"Relaxed Dogs\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder for the specific class you want to plot\n",
    "class_folder = '../data/train_data/sad'\n",
    "\n",
    "# Get a list of image files in the specified folder\n",
    "image_files = glob.glob(class_folder + '/*.jpg')[:5]  # Limit to the first 5 images\n",
    "\n",
    "# Create subplots for the images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(image_files), figsize=(12, 3))\n",
    "\n",
    "# Load and plot the images\n",
    "for i, filename in enumerate(image_files):\n",
    "    image = ski.io.imread(filename)\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')  # Hide axis\n",
    "\n",
    "plt.suptitle(\"Sad Dogs\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2654203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder for the specific class you want to plot\n",
    "class_folder = '../data/angry'\n",
    "\n",
    "# Get a list of image files in the specified folder\n",
    "image_files = glob.glob(class_folder + '/*.jpg')[:5]  # Limit to the first 5 images\n",
    "\n",
    "# Create subplots for the images\n",
    "fig, axs = plt.subplots(nrows=1, ncols=len(image_files), figsize=(12, 3))\n",
    "\n",
    "# Load and plot the images\n",
    "for i, filename in enumerate(image_files):\n",
    "    image = ski.io.imread(filename)\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].axis('off')  # Hide axis\n",
    "\n",
    "plt.suptitle(\"Angry Dogs\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff95d5",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016456c9",
   "metadata": {},
   "source": [
    "### 1. Baseline CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and batch size\n",
    "input_size = (32, 32)\n",
    "batch_size = 32\n",
    "\n",
    "# Perform data augmentation on training images\n",
    "train_datagen_baseline = ImageDataGenerator(rescale = 1.0 / 255.0, # Rescale pixel values to the range [0, 1]\n",
    "                             rotation_range = 80,      # Degree range for random rotations\n",
    "                             width_shift_range = 0.5,  # Fraction of total width for random horizontal shifts\n",
    "                             height_shift_range = 0.5, # Fraction of total height for random vertical shifts\n",
    "                             shear_range = 0.5,        # Shear intensity for random shear transformations\n",
    "                             zoom_range = 0.5,         # Random zoom range\n",
    "                             horizontal_flip = True,   # Randomly flip inputs horizontally\n",
    "                             fill_mode='nearest')       # Strategy for filling in newly created pixels after rotation or shifts\n",
    "\n",
    "# Note that the validation data should not be augmented\n",
    "test_datagen_baseline = ImageDataGenerator(rescale = 1.0/255.)   \n",
    "                                            \n",
    "                                            \n",
    "# Flow training images in batches using train_datagen_baseline generator                                   \n",
    "train_generator = train_datagen_baseline.flow_from_directory(train_dir,\n",
    "                                                             batch_size = batch_size,\n",
    "                                                             target_size = input_size,\n",
    "                                                             class_mode='categorical',\n",
    "                                                             subset='training')\n",
    "                                            \n",
    "# Flow validation images in batches using test_datagen_baseline generator\n",
    "val_generator = test_datagen_baseline.flow_from_directory(validation_dir,\n",
    "                                                          batch_size = batch_size,\n",
    "                                                          target_size = input_size,\n",
    "                                                          class_mode='categorical',\n",
    "                                                          subset='validation')\n",
    "                                            \n",
    "\n",
    "# Instantiate model\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_size + (3,)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')  # Use 'softmax' for multi-class classification\n",
    "])\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "cnn.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy', # Use 'categorical_crossentropy' for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Model Summary: \", cnn.summary())\n",
    "\n",
    "# Train the model\n",
    "history = cnn.fit(train_generator,\n",
    "                  epochs=20,\n",
    "                  validation_data=val_generator)\n",
    "\n",
    "# Evaluate the model on the training and validation sets\n",
    "train_accuracy = cnn.evaluate(train_generator)[1]\n",
    "test_accuracy = cnn.evaluate(val_generator)[1]\n",
    "\n",
    "print(\"Baseline model Train accuracy:\", train_accuracy)\n",
    "print(\"Baseline model Validation accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf37955",
   "metadata": {},
   "source": [
    "### 2. Pre-Trained VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfeb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and batch size\n",
    "input_size = (224, 224)\n",
    "batch_size = 20\n",
    "\n",
    "# Perform data augmentation on training images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40, \n",
    "                                   width_shift_range = 0.2, \n",
    "                                   height_shift_range = 0.2, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "# Flow training images in batches using train_datagen generator\n",
    "train = train_datagen.flow_from_directory(train_dir,\n",
    "                                          batch_size = batch_size,\n",
    "                                          target_size = input_size,\n",
    "                                          class_mode = 'categorical', # Use 'categorical' for multi-class classification\n",
    "                                          subset = 'training')\n",
    "\n",
    "# Flow validation images in batches using test_datagen generator\n",
    "val = test_datagen.flow_from_directory(validation_dir,\n",
    "                                       batch_size = batch_size,\n",
    "                                       target_size = input_size,\n",
    "                                       class_mode = 'categorical',\n",
    "                                       subset='validation')\n",
    "\n",
    "# Instantiate pre-trained VGG16 model\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16(include_top=False,\n",
    "                                                weights=\"imagenet\",\n",
    "                                                input_shape=(224,224,3))\n",
    "# Add Dense Layer to VGG16 model\n",
    "model = Sequential([vgg16_model,\n",
    "                    Flatten(),\n",
    "                    Dense(4, activation = \"softmax\")]) # Use 'softmax' for multi-class classification\n",
    "\n",
    "model.layers[0].trainable = False\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "\n",
    "print(\"Model Summary: \", model.summary())\n",
    "\n",
    "# Train the model\n",
    "history =  model.fit(train,\n",
    "                    epochs=20,\n",
    "                    callbacks=[lr_callbacks],\n",
    "                    validation_data=val)\n",
    "\n",
    "# Evaluate the model on the training and validation sets\n",
    "train_accuracy = model.evaluate(train)[1]\n",
    "test_accuracy = model.evaluate(val)[1]\n",
    "\n",
    "print(\"VGG16 Train accuracy:\", train_accuracy)\n",
    "print(\"VGG16 Validation accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have true labels and predicted labels as numpy arrays\n",
    "# true_labels = ...\n",
    "# predicted_labels = ...\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix as a heatmap\n",
    "class_names = ['Angry', 'Curious', 'Happy', 'Relaxed', 'Sad']  # Replace with your class names\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a validation_generator that yields batches of validation data and labels\n",
    "validation_data, true_labels = validation_generator.next()\n",
    "\n",
    "# Make predictions using your trained model\n",
    "predictions = cnn.predict(validation_data)\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Find indices where predicted labels don't match true labels\n",
    "misclassified_indices = np.where(predicted_labels != true_labels)[0]\n",
    "\n",
    "# Get the misclassified data and true labels\n",
    "misclassified_data = validation_data[misclassified_indices]\n",
    "misclassified_true_labels = true_labels[misclassified_indices]\n",
    "misclassified_predicted_labels = predicted_labels[misclassified_indices]\n",
    "\n",
    "# Convert numerical labels to class names if necessary\n",
    "class_names = ['Angry', 'Curious', 'Happy', 'Relaxed', 'Sad']  # Replace with your class names\n",
    "misclassified_true_class_names = [class_names[int(label)] for label in misclassified_true_labels.ravel()]\n",
    "misclassified_predicted_class_names = [class_names[int(label)] for label in misclassified_predicted_labels.ravel()]\n",
    "\n",
    "# Print or further analyze misclassified data and true labels\n",
    "for i in range(len(misclassified_indices)):\n",
    "    print(f\"True Label: {misclassified_true_class_names[i]}, Predicted Label: {misclassified_predicted_class_names[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0059fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model (without the training history)\n",
    "cnn.save(\"cnn_model.keras\")\n",
    "\n",
    "# Pickle out the CNN model file path for deployment on Streamlit\n",
    "with open(\"../streamlit/cnn_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(\"cnn_model.keras\", model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57a817",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the uploaded image\n",
    "uploaded_image_path = \"../testdata/test_image.jpg\"\n",
    "\n",
    "# Read and display the uploaded image\n",
    "uploaded_image = Image.open(uploaded_image_path)\n",
    "plt.imshow(uploaded_image)\n",
    "plt.axis('off')  # Turn off axis numbers and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class labels\n",
    "class_labels = ['Angry', 'Curious', 'Happy', 'Relaxed', 'Sad']\n",
    "\n",
    "# Read the uploaded image\n",
    "image = keras_image.load_img(uploaded_image_path, target_size=(32, 32))\n",
    "image_array = keras_image.img_to_array(image)\n",
    "image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "image_array /= 255.0  # Normalize the pixel values\n",
    "\n",
    "# Make prediction\n",
    "predictions = cnn.predict(image_array)\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "# Display the predicted class label\n",
    "print(f\"Predicted Class: {predicted_class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b6b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
